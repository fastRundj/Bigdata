Kibana理解：

1、Kibana只需要安装在一个服务器上，相当于一个web交互平台；
2、X-Pack是集成在Kibana里的一个与ES进行交互的多个插件的集合，因此X-Pack需要安装在Kibana节点的Kibana里面和所有ES节点的ES里面。
3、Kibana服务可以安装一个或多个，可以安装在客户端、本地windows，安装在集群之外！Kibana 的配置很大程度上依赖于您的使用场景。如果只有自己使用，
可以在自己的机器上运行 Kibana，配置它指向任何您想要交互的 Elasticsearch 实例。相反，如果有大量的 Kibana 使用者，需要多个 Kibana
实例连接至同一个 Elasticsearch 节点，来保证负载均衡。
尽管 Kibana 不是非常耗费资源，我们仍然建议运行 Kibana 的节点和 Elasticsearch 数据或主节点分开。在 Elasticsearch 集群中分配 Kibana，
可以在 Elasticsearch 客户端节点上运行 Kibana。
4、创建索引模式


ES理解及使用：

一个 Elasticsearch 集群可以 包含多个 索引 ，相应的每个索引可以包含多个 类型 。 这些不同的类型存储着多个 文档 ，每个文档又有 多个 属性 。
1、
索引：数据库
类型：表
文档：一条记录

2、倒排索引；每个字段都加了倒排索引，类似表的索引类型：BTRee
3、_score属性，相关性排序；
4、搜索中的请求json体、分析聚合；
5、一个运行中的 Elasticsearch 实例称为一个 节点，而集群是由一个或者多个拥有相同 cluster.name 配置的节点组成， 它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。
当一个节点被选举成为 主 节点时， 它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。我们的示例集群就只有一个节点，所以它同时也成为了主节点。
作为用户，我们可以将请求发送到 集群中的任何节点 ，包括主节点。 每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。


6、扩容：增加分片
我们往 Elasticsearch 添加数据时需要用到 索引 —— 保存相关数据的地方。 索引实际上是指向一个或者多个物理 分片 的 逻辑命名空间 。
一个 分片 是一个底层的 工作单元 ，它仅保存了 全部数据中的一部分。 在分片内部机制中，我们将详细介绍分片是如何工作的，而现在我们只需知道一个分片是一个 Lucene 的实例，以及它本身就是一个完整的搜索引擎。 我们的文档被存储和索引到分片内，但是应用程序是直接与索引而不是与分片进行交互。
Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。 当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。
一个分片可以是 主 分片或者 副本 分片。 索引内任意一个文档都归属于一个主分片，所以主分片的数目决定着索引能够保存的最大数据量。

一个副本分片只是一个主分片的拷贝。 副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。
在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改。
集群的健康状况为 yellow 则表示全部 主 分片都正常运行（集群可以正常服务所有请求），但是 副本 分片没有全部处在正常状态。 实际上，所有3个副本分片都是 unassigned —— 它们都没有被分配到任何节点。

主分片的数目在索引创建时 就已经确定了下来。实际上，这个数目定义了这个索引能够 存储 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作——搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。
在运行中的集群上是可以动态调整副本分片数目的 ，我们可以按需伸缩集群。三个主分片，让我们把副本数从默认的 1 增加到 2，则会有9个分片。

7、索引、类型：
索引名，这个名字必须小写，不能以下划线开头，不能包含逗号；
数据可能在索引中只是松散的组合在一起，但是通常明确定义一些数据中的子分区是很有用的。 例如，所有的产品都放在一个索引中，但是你有许多不同的产品类别，比如 "electronics" 、 "kitchen" 和 "lawn-care"。
这些文档共享一种相同的（或非常相似）的模式：他们有一个标题、描述、产品代码和价格。他们只是正好属于“产品”下的一些子类。
Elasticsearch 公开了一个称为 types （类型）的特性，它允许您在索引中对数据进行逻辑分区。不同 types 的文档可能有不同的字段，但最好能够非常相似。 我们将在 类型和映射 中更多的讨论关于 types 的一些应用和限制。
一个 _type 命名可以是大写或者小写，但是不能以下划线或者句号开头，不应该包含逗号， 并且长度限制为256个字符. 我们使用 blog 作为类型名举例。

8、_version：
在 Elasticsearch 中每个文档都有一个版本号。当每次对文档进行修改时（包括删除）， _version 的值会递增。

在请求的查询串参数中加上 pretty 参数， 正如前面的例子中看到的，这将会调用 Elasticsearch 的 pretty-print 功能，该功能 使得 JSON 响应体更加可读。

9、_source=取回指定字段；
HEAD检查文档是否存在；

10、文档更新：
在 Elasticsearch 中文档是不可改变的，不能修改它们。

整个文档更新：
使用:
PUT /website/blog/123
{"title": "My first blog entry",
  "text":  "I am starting to get the hang of this...",
  "date":  "2014/01/02"
}
进行更新，内部是把这条文档标记已删除，然后再索引当前的这个文档，因此这两个文档是完全独立的，不能相互影响；


_udate部分字段更新：也不能违背对文档的直接修改原则；

内其实部经过了4个过程：
1）从旧文档构建 JSON
2）更改该 JSON
3）删除旧文档
4）索引一个新文档
POST /website/blog/1/_update
{
   "doc" : {
      "tags" : [ "testing" ],
      "views": 0
   }
}
update 请求最简单的一种形式是接收文档的一部分作为 doc 的参数， 它只是与现有的文档进行合并。
对象被合并到一起，覆盖现有的字段，增加新的字段。

删除文档：DELETE /website/blog/123
取回多个文档：
mget API 来将这些检索请求放在一个请求中，将比逐个文档请求更快地检索到全部文档。
mget API 要求有一个 docs 数组作为参数，每个 元素包含需要检索文档的元数据，
包括 _index 、 _type 和 _id 。如果你想检索一个或者多个特定的字段，那么你可以通过 _source 参数来指定这些字段的名字：
GET /_mget
{
   "docs" : [
      {
         "_index" : "website",
         "_type" :  "blog",
         "_id" :    2
      },
      {
         "_index" : "website",
         "_type" :  "pageviews",
         "_id" :    1,
         "_source": "views"
      }
   ]
}

该响应体也包含一个 docs 数组 ， 对于每一个在请求中指定的文档，这个数组中都包含有一个对应的响应，且顺序与请求中的顺序相同。 其中的每一个响应都和使用单个 get request 请求所得到的响应体相同：

{
   "docs" : [
      {
         "_index" :   "website",
         "_id" :      "2",
         "_type" :    "blog",
         "found" :    true,
         "_source" : {
            "text" :  "This is a piece of cake...",
            "title" : "My first external blog entry"
         },
         "_version" : 10
      },
      {
         "_index" :   "website",
         "_id" :      "1",
         "_type" :    "pageviews",
         "found" :    true,
         "_version" : 2,
         "_source" : {
            "views" : 2
         }
      }
   ]
}

如果想检索的数据都在相同的 _index 中（甚至相同的 _type 中），则可以在 URL 中指定默认的 /_index 或者默认的 /_index/_type 。

你仍然可以通过单独请求覆盖这些值：

GET /website/blog/_mget
{
   "docs" : [
      { "_id" : 2 },
      { "_type" : "pageviews", "_id" :   1 }
   ]
}
拷贝为 CURL在 SENSE 中查看
事实上，如果所有文档的 _index 和 _type 都是相同的，你可以只传一个 ids 数组，而不是整个 docs 数组：

GET /website/blog/_mget
{
   "ids" : [ "2", "1" ]
}
注意，我们请求的第二个文档是不存在的。我们指定类型为 blog ，但是文档 ID 1 的类型是 pageviews ，这个不存在的情况将在响应体中被报告：

{
  "docs" : [
    {
      "_index" :   "website",
      "_type" :    "blog",
      "_id" :      "2",
      "_version" : 10,
      "found" :    true,
      "_source" : {
        "title":   "My first external blog entry",
        "text":    "This is a piece of cake..."
      }
    },
    {
      "_index" :   "website",
      "_type" :    "blog",
      "_id" :      "1",
      "found" :    false
    }
  ]
}

11、批量操作：https://www.elastic.co/guide/cn/elasticsearch/guide/current/bulk.html
mget 合并多个get请求，可以使我们一次取回多个文档同样的方式。
bulk API 允许在单个步骤中进行多次 create 、 index 、 update 或 delete 请求。

12、路由一个文档到一个分片中
当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片 1 还是分片 2 中呢？
首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的：
shard = hash(routing) % number_of_primary_shards
routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到 余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。
这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。
所有的文档 API（ get 、 index 、 delete 、 bulk 、 update 以及 mget ）都接受一个叫做 routing 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档——例如所有属于同一个用户的文档——都被存储到同一个分片中。
我们也会在扩容设计这一章中详细讨论为什么会有这样一种需求。
13、新建、索引和删除文档：https://www.elastic.co/guide/cn/elasticsearch/guide/current/distrib-write.html
新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片。
在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。
14、主分片到副本分片的复制
当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。
15、使用 mget 取回多个文档 和 使用 bulk 修改多个文档 过程：https://www.elastic.co/guide/cn/elasticsearch/guide/current/distrib-multi-doc.html
mget 和 bulk API 的 模式类似于单文档模式。区别在于协调节点知道每个文档存在于哪个分片中，整个请求中，哪些请求找的是分片1，哪些请求找的是分片2等等，将这些
请求同一分片的单个请求再合并成一个“多文档请求”，去请求对应的分片，也即是将“整个多文档请求”分解成 多个“对应分片” 的“多文档请求”，并且将这些请求并行转发到每个参与节点。
协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端

16、搜索结果，参数说明：https://www.elastic.co/guide/cn/elasticsearch/guide/current/empty-search.html
16、多索引、多类型搜索：
/_search
在所有的索引中搜索所有的类型
/gb/_search
在 gb 索引中搜索所有的类型
/gb,us/_search
在 gb 和 us 索引中搜索所有的文档
/g*,u*/_search
在任何以 g 或者 u 开头的索引中搜索所有的类型
/gb/user/_search
在 gb 索引中搜索 user 类型
/gb,us/user,tweet/_search
在 gb 和 us 索引中搜索 user 和 tweet 类型
/_all/user,tweet/_search
在所有的索引中搜索 user 和 tweet 类型
17、在分布式系统中深度分页
考虑到分页过深以及一次请求太多结果的情况，结果集在返回之前先进行排序。 但请记住一个请求经常跨越多个分片，每个分片都产生自己的排序结果，这些结果需要进行集中排序以保证整体顺序是正确的。
理解为什么深度分页是有问题的，我们可以假设在一个有 5 个主分片的索引中搜索。 当我们请求结果的第一页（结果从 1 到 10 ），每一个分片产生前 10 的结果，并且返回给 协调节点 ，协调节点对 50 个结果排序得到全部结果的前 10 个。
现在假设我们请求第 1000 页--结果从 10001 到 10010 。所有都以相同的方式工作除了每个分片不得不产生前10010个结果以外。 然后协调节点对全部 50050 个结果排序最后丢弃掉这些结果中的 50040 个结果。
可以看到，在分布式系统中，对结果排序的成本随分页的深度成指数上升。这就是 web 搜索引擎对任何查询都不要返回超过 1000 个结果的原因。
18、轻量搜索：
有两种形式的 搜索 API：一种是 “轻量的” 查询字符串 版本，要求在查询字符串中传递所有的 参数，另一种是更完整的 请求体 版本，
要求使用 JSON 格式和更丰富的查询表达式作为搜索语言。

19、
mapping的正删改查：不能修改mapping中已存在域（属性）的类型，可向mapping中新增属性。
mapping限制了属性的类别：整型，浮点型，日期，boolean，string,除了string其他都是精确值，但string也可以设置成精确值或全文。
对全文搜索时，搜索词和全文类的属性都要先经过分词。而精确值不需要进行分词，要完全匹配。
除了我们提到的整型，浮点型，日期，boolean，string数据类型， JSON 还有 null 值，数组，和对象，这些 Elasticsearch 都是支持的。
使用 analyze API测试分词器：查看不同的属性使用不同分词器时，产生的词条。


20、Es的一个索引中，最终会共享一个映射，因此一个索引中的“不同类型中”也不允许有名字相同但属性不同的字段！！！
这导致了一个有趣的思想实验： 如果有两个不同的类型，每个类型都有同名的字段，但映射不同（例如：一个是字符串一个是数字），将会出现什么情况？
简单回答是，Elasticsearch 不会允许你定义这个映射。当你配置这个映射时，将会出现异常。
详细回答是，每个 Lucene 索引中的所有字段都包含一个单一的、扁平的模式。一个特定字段可以映射成 string 类型也可以是 number 类型，但是不能两者兼具。
因为类型是 Elasticsearch添加的 优于 Lucene 的额外机制（以元数据 _type 字段的形式），在 Elasticsearch 中的所有类型最终都共享相同的映射。
对于整个索引，映射在本质上被 扁平化 成一个单一的、全局的模式。这就是为什么两个类型不能定义冲突的字段：当映射被扁平化时，Lucene 不知道如何去处理。

类型不适合 完全不同类型的数据 。如果两个类型的字段集是互不相同的，这就意味着索引中将有一半的数据是空的（字段将是 稀疏的 ），最终将导致性能问题。
在这种情况下，最好是使用两个单独的索引。

21、分片内部索引：倒排索引的不变形性？
22、布尔过滤器：嵌套过滤器，bool过滤器可以放入别的过滤器中；
一个 bool 过滤器由三部分组成：
{
   "bool" : {
      "must" :     [],
      "should" :   [],
      "must_not" : [],
   }
}


https://www.elastic.co/guide/cn/elasticsearch/guide/current/_finding_multiple_exact_values.html
精确值查询：term查询，只去查询倒排索引中的词项，有的字段值是列表[‘search’,'sport']，包含多个词，因此
只需要搜索的‘search’在该字段值生成的倒排索引中（[‘search’,'sport']在倒排索引中有‘search’,'sport'两个词）即可被搜索到，
无需搜索的词=[‘search’,'sport']。


23、ES5.0新特性: https://blog.csdn.net/jianghuxiaojin/article/details/53174305

5.0新特性：string改为keyword、text;另外string类型暂时还在的，6.0会移除。
keyword：相当于type:string，index:not_analyzed
text：相当于type:string，index:analyzed



域最重要的属性是 type 。对于不是 string 的域，你一般只需要设置 type ：

{
    "number_of_clicks": {
        "type": "integer"
    }
}
默认， string 类型域会被认为包含全文。就是说，它们的值在索引前，会通过 一个分析器，针对于这个域的查询在搜索前也会经过一个分析器。

string 域映射的两个最重要 属性是 index 和 analyzer 。

index
index 属性控制怎样索引字符串。它可以是下面三个值：

analyzed
首先分析字符串，然后索引它。换句话说，以全文索引这个域。
not_analyzed
  索引这个域，所以它能够被搜索，但索引的是精确值。不会对它进行分析。
no
不索引这个域。这个域不会被搜索到。
string 域 index 属性默认是 analyzed 。如果我们想映射这个字段为一个精确值，我们需要设置它为 not_analyzed ：

{
    "tag": {
        "type":     "string",
        "index":    "not_analyzed"
    }
}
注意:
其他简单类型（例如 long ， double ， date 等）也接受 index 参数，但有意义的值只有 no 和 not_analyzed ， 因为它们永远不会被分析。


string类型的字段，默认会有两种索引类型：text，keyword
"trial_request": {
            "type": "text",
            "fields": {
              "keyword": {
                "type": "keyword",
                "ignore_above": 256
              }
            }
          }
这种是multi-fields 对一个field设置多种索引，es会默认为trial_request添加名称为keyword（名称可以改变）的字段，
类型为keyword，使用trial_request.keyword字段用于排序、聚合。

keyword只有string类型的字段有 其他的 number date是不解析的
那几个对号 分别是 可搜索 可聚合 可分词 只有no_analyzed的字段可以聚合 keyword的字段不可以分词
 如果你没有设置mapping 在put数据的时候es会默认给每个string字段加keyword类型