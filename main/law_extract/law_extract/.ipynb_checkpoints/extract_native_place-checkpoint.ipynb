{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*-coding:utf8-*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyltp import Segmentor\n",
    "from pyltp import Postagger\n",
    "from pyltp import NamedEntityRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load('/home/sherlock/Documents/ltp_data/cws.model')\n",
    "#实例化词性工具\n",
    "postagger = Postagger() # 初始化实例\n",
    "postagger.load('/home/sherlock/Documents/ltp_data/pos.model')  # 加载模型\n",
    "recognizer = NamedEntityRecognizer()\n",
    "recognizer.load('/home/sherlock/Documents/ltp_data/ner.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wdseg(inputstr,ret_type):\n",
    "\n",
    "\n",
    "    words = segmentor.segment(inputstr)  # 分词\n",
    "    if ret_type == 'str':\n",
    "        seg_word = ' '.join(words)\n",
    "    if ret_type == 'lst':\n",
    "        seg_word = ' '.join(words)\n",
    "        seg_word = seg_word.split()\n",
    "\n",
    "    #segmentor.release()  # 释放模型\n",
    "    return seg_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "des_path = '/media/sherlock/new30/law/jun28InfoExtractor/tb_doc_add3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add3_law_df = pd.read_csv(des_path)\n",
    "add3_law_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dd,np in enumerate(add3_law_df.native_place.tolist()):\n",
    "    if not isinstance(np,float) and len(np) >0:\n",
    "        print dd\n",
    "        print np\n",
    "        print len(np)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print add3_law_df.loc[876,'native_place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print add3_law_df.loc[876,'party_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_words = wdseg( (add3_law_df.loc[977,'party_info']).encode('utf8'),'lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_native_palce(info_seg_list):\n",
    "    '''提取籍贯，常见的句式是，籍贯XX市，出生于XX市，生于XX市，XX人，XX市出生\n",
    "    输入：分词list,\n",
    "    step1生成postaglist,\n",
    "    step2找出逗号句号的index，这样可以分出句子，\n",
    "    step3找出籍贯， 出生，人等关键词的index\n",
    "    step4把signal_word's index匹配进第一步的句子中\n",
    "    step5然后找出句子中的NS（地点）\n",
    "    step6输出 地点组成的string'''\n",
    "    def postaglist(info_seg_list):\n",
    "        postag = postagger.postag(info_seg_list)\n",
    "        postag_list = '\\t'.join(postag).split('\\t')\n",
    "        return postag_list\n",
    "\n",
    "    def comma_prd_index(info_seg_list):\n",
    "        com_prd_idx = [idx for idx,v in enumerate(info_seg_list) if v=='，'or v =='。' or v==',' or v=='.']\n",
    "        return com_prd_idx\n",
    "\n",
    "    def find_deft_loc(info_seg_list):\n",
    "        dft_index = [idx for idx,dft in enumerate(info_seg_list) if u'被告'in dft]\n",
    "        return dft_index[0]\n",
    "\n",
    "    def find_pltf_loc(info_seg_list):\n",
    "        pltf_index = [idx for idx,pltf in enumerate(info_seg_list) if u'原告' in pltf]\n",
    "        return pltf_index\n",
    "\n",
    "    def sgl_word_index(info_seg_list):\n",
    "        #唐山县人民法院会被认为是出生地\n",
    "        #如果party_info中有原告XX，出生于XX，\n",
    "        #被告人窦某某，47岁，出生于吉林省蛟河市，户籍所在地蛟河市，现住蛟河市\n",
    "        jg_singal_words3 = u\"籍\"\n",
    "        jg_singal_words2 = u\"人\"\n",
    "        jg_singal_words1 = u\"生\"\n",
    "\n",
    "        #jg_sgl_word_list = jg_singal_words.split(',')\n",
    "        sgl_word_idx = [ ]\n",
    "        #for index, sgl in enumerate(jg_sgl_word_list):\n",
    "        for wd_idx,ww in enumerate(info_seg_list):\n",
    "            if jg_singal_words1 in ww:\n",
    "                sgl_word_idx.append(wd_idx)\n",
    "        #jg_singal_words2 = u'人'\n",
    "        #jg_sgl_word_list2 = jg_singal_words2.split()\n",
    "        #for wd_idx2,ww in enumerate(info_seg_list):\n",
    "            if jg_singal_words2 in ww:\n",
    "                if info_seg_list[wd_idx+1] ==',' or info_seg_list[wd_idx+1]=='.'or info_seg_list[wd_idx+1]=='，' or info_seg_list[wd_idx+1]=='。':\n",
    "                    sgl_word_idx.append(wd_idx)\n",
    "            if jg_singal_words3 in ww:\n",
    "                    sgl_word_idx.append(wd_idx)\n",
    "        print 'inti_sgl_word index' ,sgl_word_idx\n",
    "\n",
    "        dft_start = find_deft_loc(info_seg_list)\n",
    "        sgl_word_start = np.searchsorted(sgl_word_idx,dft_start,'left')\n",
    "        #add pltf index list, and dft start to insert into the list,\n",
    "        #if the plft list's length is larger than zero and the dft inserted index is\n",
    "        # less than the plft length ,    then add the next pltf index to the sgl_word_idx\n",
    "        pltf_idx = find_pltf_loc(info_seg_list)\n",
    "        if len(pltf_idx)>0 :\n",
    "            dft_into_pltf_index = np.searchsorted(pltf_idx,dft_start,'left')\n",
    "            if dft_into_pltf_index < len(pltf_idx):\n",
    "\n",
    "                sgl_word_end = pltf_idx[dft_into_pltf_index]\n",
    "                sgl_word_idx = sgl_word_idx[sgl_word_start:sgl_word_end]\n",
    "            else:\n",
    "                sgl_word_idx = sgl_word_idx[sgl_word_start:]\n",
    "\n",
    "        else:\n",
    "\n",
    "            sgl_word_idx = sgl_word_idx[sgl_word_start:]\n",
    "        for ii in  sgl_word_idx:print info_seg_list[ii]\n",
    "        return sgl_word_idx\n",
    "\n",
    "    def sgl_range(sgl_word_index,comma_prd_index):\n",
    "        sgl_range=[]\n",
    "        for sg in sgl_word_index:\n",
    "            start = np.searchsorted(comma_prd_index,sg,'left')\n",
    "            print start\n",
    "            print len(comma_prd_index)\n",
    "            if start >0:\n",
    "                start_range= comma_prd_index[start-1]\n",
    "                if start <len(comma_prd_index)-1:\n",
    "                    end_range = comma_prd_index[start]\n",
    "                else:\n",
    "                    end_range = comma_prd_index[-1]\n",
    "                print 'start_range is' , start_range\n",
    "                print 'end_range is',end_range\n",
    "    #if start == 0:\n",
    "       # start_range = 0\n",
    "        #end_range = com_prd_idx[0]\n",
    "                sgl_range.append((start_range,end_range))\n",
    "            print sgl_range\n",
    "        return sgl_range\n",
    "\n",
    "    def find_loc(sql_range,postag_list,info_seg_list):\n",
    "        jg_str = ''\n",
    "        for i in sgl_range:\n",
    "            jg_str2 = ''\n",
    "            if 'ns' in postag_list[i[0]:i[1]]:\n",
    "                for ix,pp in enumerate(postag_list[i[0]:i[1]]):\n",
    "                    if pp == 'ns':\n",
    "                        jg_ns =  info_seg_list[i[0]:i[1]][ix]\n",
    "                        print jg_ns\n",
    "                        jg_str2 = jg_str2+jg_ns\n",
    "                        print jg_str2\n",
    "            jg_str = jg_str + jg_str2 +' '\n",
    "        return jg_str\n",
    "\n",
    "    postag_list = postaglist(info_seg_list)\n",
    "    com_prd_index = comma_prd_index(info_seg_list)\n",
    "    sgl_index = sgl_word_index(info_seg_list)\n",
    "    sgl_range = sgl_range(sgl_index, com_prd_index)\n",
    "    jg_str = find_loc(sgl_range, postag_list, info_seg_list)\n",
    "    return jg_str\n",
    "    # the native_born_place is still ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_native_palce(info_seg_list):\n",
    "    '''提取籍贯，常见的句式是，籍贯XX市，出生于XX市，生于XX市，XX人，XX市出生\n",
    "    输入：分词list,\n",
    "    step1生成postaglist,\n",
    "    step2找出逗号句号的index，这样可以分出句子，\n",
    "    step3找出籍贯， 出生，人等关键词的index\n",
    "    step4把signal_word's index匹配进第一步的句子中\n",
    "    step5然后找出句子中的NS（地点）\n",
    "    step6输出 地点组成的string'''\n",
    "    def postaglist(info_seg_list):\n",
    "        postag = postagger.postag(info_seg_list)\n",
    "        postag_list = '\\t'.join(postag).split('\\t')\n",
    "        return postag_list\n",
    "\n",
    "    def comma_prd_index(info_seg_list):\n",
    "        com_prd_idx = [idx for idx,v in enumerate(info_seg_list) if v=='，'or v =='。' or v==',' or v=='.']\n",
    "        return com_prd_idx\n",
    "\n",
    "    def find_deft_loc(info_seg_list):\n",
    "        dft_index = [idx for idx,dft in enumerate(info_seg_list) if u'被告'in dft]\n",
    "        return dft_index\n",
    "\n",
    "    def find_pltf_loc(info_seg_list):\n",
    "        pltf_index = [idx for idx,pltf in enumerate(info_seg_list) if u'原告' in pltf]\n",
    "        return pltf_index\n",
    "\n",
    "    def sgl_word_index(dft_start,info_seg_list):\n",
    "        #唐山县人民法院会被认为是出生地\n",
    "        #如果party_info中有原告XX，出生于XX，\n",
    "        #被告人窦某某，47岁，出生于吉林省蛟河市，户籍所在地蛟河市，现住蛟河市\n",
    "        jg_singal_words3 = u\"籍\"\n",
    "        jg_singal_words2 = u\"人\"\n",
    "        jg_singal_words1 = u\"生\"\n",
    "        jg_singal_blackwords =u\"人民\"\n",
    "\n",
    "        #jg_sgl_word_list = jg_singal_words.split(',')\n",
    "        sgl_word_idx = [ ]\n",
    "        #for index, sgl in enumerate(jg_sgl_word_list):\n",
    "        for wd_idx,ww in enumerate(info_seg_list):\n",
    "            if jg_singal_words1 in ww:\n",
    "                sgl_word_idx.append(wd_idx)\n",
    "        #jg_singal_words2 = u'人'\n",
    "        #jg_sgl_word_list2 = jg_singal_words2.split()\n",
    "        #for wd_idx2,ww in enumerate(info_seg_list):\n",
    "            elif jg_singal_words2 in ww and not jg_singal_blackwords in ww :\n",
    "                if info_seg_list[wd_idx+1] ==',' or info_seg_list[wd_idx+1]=='.'or info_seg_list[wd_idx+1]=='，' or info_seg_list[wd_idx+1]=='。':\n",
    "                    sgl_word_idx.append(wd_idx)\n",
    "            elif jg_singal_words3 in ww:\n",
    "                    sgl_word_idx.append(wd_idx)\n",
    "        print 'inti_sgl_word index' ,sgl_word_idx\n",
    "\n",
    "        ##dft_start = find_deft_loc(info_seg_list)\n",
    "        sgl_word_start = np.searchsorted(sgl_word_idx,dft_start,'left')\n",
    "        #add pltf index list, and dft start to insert into the list,\n",
    "        #if the plft list's length is larger than zero and the dft inserted index is\n",
    "        # less than the plft length ,    then add the next pltf index to the sgl_word_idx\n",
    "        pltf_idx = find_pltf_loc(info_seg_list)\n",
    "        if len(pltf_idx)>0 :\n",
    "            dft_into_pltf_index = np.searchsorted(pltf_idx,dft_start,'left')\n",
    "            if dft_into_pltf_index < len(pltf_idx):\n",
    "\n",
    "                sgl_word_end = pltf_idx[dft_into_pltf_index]\n",
    "                sgl_word_idx = sgl_word_idx[sgl_word_start:sgl_word_end]\n",
    "            else:\n",
    "                sgl_word_idx = sgl_word_idx[sgl_word_start:]\n",
    "\n",
    "        else:\n",
    "\n",
    "            sgl_word_idx = sgl_word_idx[sgl_word_start:]\n",
    "        if len(sgl_word_idx)>0:\n",
    "            sgl_word_idx = sgl_word_idx[0]\n",
    "        #print info_seg_list[sgl_word_idx]\n",
    "        return sgl_word_idx\n",
    "\n",
    "    def sgl_range(sgl_word_index,comma_prd_index):\n",
    "        sgl_range=[]\n",
    "        for sg in sgl_word_index:\n",
    "            start = np.searchsorted(comma_prd_index,sg,'left')\n",
    "            print start\n",
    "            print len(comma_prd_index)\n",
    "            if start >0:\n",
    "                start_range= comma_prd_index[start-1]\n",
    "                if start <len(comma_prd_index)-1:\n",
    "                    end_range = comma_prd_index[start]\n",
    "                else:\n",
    "                    end_range = comma_prd_index[-1]\n",
    "                print 'start_range is' , start_range\n",
    "                print 'end_range is',end_range\n",
    "    #if start == 0:\n",
    "       # start_range = 0\n",
    "        #end_range = com_prd_idx[0]\n",
    "                sgl_range.append((start_range,end_range))\n",
    "            print sgl_range\n",
    "        return sgl_range\n",
    "\n",
    "    def find_loc(sql_range,postag_list,info_seg_list):\n",
    "        jg_str = ''\n",
    "        for i in sgl_range:\n",
    "            jg_str2 = ''\n",
    "            if 'ns' in postag_list[i[0]:i[1]]:\n",
    "                for ix,pp in enumerate(postag_list[i[0]:i[1]]):\n",
    "                    if pp == 'ns':\n",
    "                        jg_ns =  info_seg_list[i[0]:i[1]][ix]\n",
    "                        print jg_ns\n",
    "                        jg_str2 = jg_str2+jg_ns\n",
    "                        print jg_str2\n",
    "            jg_str = jg_str + jg_str2 +' '\n",
    "        return jg_str\n",
    "\n",
    "    postag_list = postaglist(info_seg_list)\n",
    "    com_prd_index = comma_prd_index(info_seg_list)\n",
    "    dft_start = find_deft_loc(info_seg_list)\n",
    "    sgl_idx = []\n",
    "    for dft in dft_start:\n",
    "\n",
    "        sgl_index = sgl_word_index(dft, info_seg_list)\n",
    "        sgl_idx.append(sgl_index)\n",
    "    sgl_range = sgl_range(sgl_idx, com_prd_index)\n",
    "    jg_str = find_loc(sgl_range, postag_list, info_seg_list)\n",
    "    return jg_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'searchsorted'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-f8d1530fa7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0madd3_law_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m977\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'party_info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnt_place_17\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_native_palce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m'native_palce final is '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt_place_17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-d8a31ac32eb8>\u001b[0m in \u001b[0;36mget_native_palce\u001b[0;34m(info_seg_list)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdft\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdft_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0msgl_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgl_word_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_seg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0msgl_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgl_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0msgl_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgl_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgl_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcom_prd_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-d8a31ac32eb8>\u001b[0m in \u001b[0;36msgl_word_index\u001b[0;34m(dft_start, info_seg_list)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m##dft_start = find_deft_loc(info_seg_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0msgl_word_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgl_word_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdft_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m#add pltf index list, and dft start to insert into the list,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m#if the plft list's length is larger than zero and the dft inserted index is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'searchsorted'"
     ]
    }
   ],
   "source": [
    "print add3_law_df.loc[977,'party_info']\n",
    "nt_place_17 = get_native_palce(info_words)\n",
    "print'native_palce final is ', nt_place_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
