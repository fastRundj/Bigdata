{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*-coding:utf8-*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "reload(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyltp import Segmentor\n",
    "from pyltp import Postagger\n",
    "from pyltp import NamedEntityRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load('/home/sherlock/Documents/ltp_data/cws.model')\n",
    "#实例化词性工具\n",
    "postagger = Postagger() # 初始化实例\n",
    "postagger.load('/home/sherlock/Documents/ltp_data/pos.model')  # 加载模型\n",
    "recognizer = NamedEntityRecognizer()\n",
    "recognizer.load('/home/sherlock/Documents/ltp_data/ner.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "des_path = '/media/sherlock/new30/law/jun28InfoExtractor/tb_doc_add3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                   3\n",
       "uuid                              1824f1ec-0184-43b6-a5cb-f6821d3afb99\n",
       "caseid                                              （2016）京0108刑初1421号\n",
       "title                                                       李进果危险驾驶罪一案\n",
       "doc_reason                                           {\"李×\": [\"危险驾驶罪\"]}\n",
       "doc_oriligigation                                          北京市海淀区人民检察院\n",
       "fact_finder                                                        NaN\n",
       "court                                                       北京市海淀区人民法院\n",
       "lawlist              [\"《中华人民共和国刑法》第一百三十三条之一第一款第（二）项\", \"《中华人民共和国刑法》第...\n",
       "record_time                                                 2016-07-21\n",
       "casedate                                                    2016-07-21\n",
       "timeline             [[\"2016-07-21\", \"立案\"], [\"2016-07-21\", \"审理\"], [...\n",
       "party_info                    公诉机关北京市海淀区人民检察院。\\n被告人李×，男，1977年9月5日出生。\\n\n",
       "defendant                                                          NaN\n",
       "plaintiff                                                          NaN\n",
       "third                                                              NaN\n",
       "trial_process        公诉机关以京海检公诉刑诉[2016]1235号起诉书指控被告人李×犯危险驾驶罪。本院适用刑事...\n",
       "trial_request        公诉机关指控：2016年7月10日22时许，被告人李×饮酒后驾驶一辆小型轿车（车牌号：×××...\n",
       "trial_reply                  被告人李×对指控事实、罪名及量刑建议没有异议并签字具结，在开庭审理过程中亦无异议。\n",
       "court_find                                                         NaN\n",
       "court_idea           本院认为，公诉机关指控被告人李×犯危险驾驶罪的事实清楚，证据确实充分，指控罪名成立，量刑建议...\n",
       "judge_result         被告人李×犯危险驾驶罪，判处拘役一个月，罚金人民币二千元。\\n（刑期自2016年7月10日起...\n",
       "judge_chief                                                        NaN\n",
       "judge_member                                                        郭照\n",
       "history                                                            NaN\n",
       "type                                                                一审\n",
       "reason_type                                                         刑事\n",
       "judge_type                                                         判决书\n",
       "result_type                                                        NaN\n",
       "doc_content          &lt;a type=&#x27;dir&#x27; name=&#x27;WBSB&#x2...\n",
       "update_time                                         2017/6/27 17:36:55\n",
       "doc_from                                                    wenshu-gov\n",
       "reason                                                            危险驾驶\n",
       "is_crawl                                                             1\n",
       "is_format                                                            1\n",
       "gender                                                              男 \n",
       "edu                                                                NaN\n",
       "nation                                                             NaN\n",
       "birth                                                       1977年9月5日 \n",
       "suspect_num                                                          1\n",
       "native_place                                                          \n",
       "year_age                                                            39\n",
       "team_crmnl                                                           0\n",
       "adult                                                                1\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add3_law_df = pd.read_csv(des_path)\n",
    "add3_law_df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10,40,1):\n",
    "    print '#############',i\n",
    "    print add3_law_df.loc[i,'court_find']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyltp import Segmentor\n",
    "from pyltp import Postagger\n",
    "from pyltp import NamedEntityRecognizer\n",
    "from collections import Counter\n",
    "\n",
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load('/home/sherlock/Documents/ltp_data/cws.model')\n",
    "#实例化词性工具\n",
    "postagger = Postagger() # 初始化实例\n",
    "postagger.load('/home/sherlock/Documents/ltp_data/pos.model')  # 加载模型\n",
    "recognizer = NamedEntityRecognizer()\n",
    "recognizer.load('/home/sherlock/Documents/ltp_data/ner.model')\n",
    "\n",
    "def wdseg(inputstr,ret_type):\n",
    "\n",
    "\n",
    "    words = segmentor.segment(inputstr)  # 分词\n",
    "    if ret_type == 'str':\n",
    "        seg_word = ' '.join(words)\n",
    "    if ret_type == 'lst':\n",
    "        seg_word = ' '.join(words)\n",
    "        seg_word = seg_word.split()\n",
    "\n",
    "    #segmentor.release()  # 释放模型\n",
    "    return seg_word\n",
    "\n",
    "def get_pos_list(seg_words):\n",
    "    print 'here'\n",
    "    print type(seg_words)\n",
    "    postags = postagger.postag(seg_words)\n",
    "    print type(postags)\n",
    "    pos_list = '\\t'.join(postags).split('\\t')\n",
    "    print type(pos_list)\n",
    "    return pos_list\n",
    "\n",
    "def pos_filter(tofilt_pos,seg_words):\n",
    "    print 'type segwords',type(seg_words)\n",
    "    postags = postagger.postag(seg_words)\n",
    "    pos_list = '\\t'.join(postags).split('\\t')\n",
    "    print pos_list\n",
    "    print 'pos list length is ',len(pos_list)\n",
    "    print 'segword length is',len(seg_words)\n",
    "    del_pos_index=set()\n",
    "    for i,pos in enumerate(pos_list):\n",
    "        if tofilt_pos in pos:\n",
    "            #print '11'\n",
    "            print i\n",
    "            del_pos_index.add(i)\n",
    "            #print seg_words\n",
    "            #print pos\n",
    "            #del seg_words[i]\n",
    "\n",
    "    seg_words =[j for i,j in enumerate(seg_words) if i not in del_pos_index]\n",
    "    print len(seg_words)\n",
    "    #print type(seg_words)\n",
    "    return seg_words\n",
    "\n",
    "\n",
    "def find_prv_idx(target_word_str,seg_word_list):\n",
    "    for idx,ww in enumerate(seg_word_list):\n",
    "        if target_word_str == ww:\n",
    "            print idx\n",
    "            return idx\n",
    "\n",
    "\n",
    "def split_by_punc(prv_word_lst):\n",
    "    dun_count =0\n",
    "    comma_count=0\n",
    "    prv_str =''\n",
    "    for i,w in enumerate(prv_word_lst):\n",
    "        if comma in w:\n",
    "            comma_count +=1\n",
    "        if dunhao in w:\n",
    "            dun_count +=1\n",
    "        \n",
    "        prv_str = ''.join(prv_word_lst)\n",
    "        print prv_str\n",
    "        if dun_count >=comma_count:\n",
    "            prv_seg_list = prv_str.split('、')\n",
    "        elif dun_count < comma_count:\n",
    "            prv_seg_list = prv_str.split('，')\n",
    "        elif dun_count == 0 or comma_count ==0:\n",
    "            prv_seg_list = prv_word_lst\n",
    "        #for i,v in enumerate(prv_seg_list):\n",
    "           # if '的' in v:\n",
    "              #  todelete_words = wdseg(v,'lst')\n",
    "                #if '的' in todelete_words:\n",
    "                   # de_index = todelete_words.index('的')\n",
    "                    #remain_words = todelete_words[de_index:]\n",
    "                    #prv_seg_list[i] =remain_words\n",
    "\n",
    "\n",
    "    return prv_seg_list\n",
    "\n",
    "\n",
    "def get_prd_index(info_seg_list):\n",
    "    prd_idx = [idx for idx,v in enumerate(info_seg_list) if v =='。' ]\n",
    "    return prd_idx\n",
    "\n",
    "def get_colon_index(info_seg_list):\n",
    "    colon_idx = [idx for idx,v in enumerate(info_seg_list) if v =='：' ]\n",
    "    return colon_idx\n",
    "\n",
    "def get_num_pos_index(pos_list):\n",
    "    num_pos = [idx for idx,v in enumerate(pos_list) if v =='m']\n",
    "    return num_pos\n",
    "\n",
    "def get_aft_colon_split_range(org_list,insert_list):\n",
    "    new_sort_list = []\n",
    "    for i in insert_list:\n",
    "        idx_int = np.searchsorted(org_list, i,side='right')\n",
    "        if idx_int >=1:\n",
    "            if i - idx_int<15:\n",
    "                range_tuple = (org_list[idx_int-1],i)\n",
    "            else:\n",
    "                range_tuple = (org_list[idx_int-1],org_list[idx_int-1]+15)\n",
    "            new_sort_list.append(range_tuple)\n",
    "    return new_sort_list\n",
    "\n",
    "def get_bef_prv_till_prd(org_list,insert_idx):\n",
    "    #new_sort_list=[]\n",
    "    idx_int = np.searchsorted(org_list,insert_idx,side='right')\n",
    "    if idx_int > 1:\n",
    "        new_sort_list = org_list[idx_int-1:idx_int+1]\n",
    "    else:\n",
    "        new_sort_list = org_list[1:3]\n",
    "    return new_sort_list\n",
    "\n",
    "comma = '，'\n",
    "peroid = '。'\n",
    "dunhao = '、'\n",
    "colon = '：'\n",
    "\n",
    "des_path = '/media/sherlock/new30/law/jun28InfoExtractor/tb_doc_add3.csv'\n",
    "law_df = pd.read_csv(des_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "courtfind = law_df.loc[35,'court_find'] #按列输出string\n",
    "print courtfind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not isinstance(courtfind, float):\n",
    "    info_words = wdseg(courtfind,'lst')#分词\n",
    "    print '###',type(info_words)\n",
    "    #pos_list = pos_list(info_words)#找出court_find的词性标注列表\n",
    "    new_info_words = pos_filter('nh', info_words)#去除人名之后的分词\n",
    "    print '###',len(new_info_words)\n",
    "    pos_list = get_pos_list(new_info_words)#找出court_find的词性标注列表\n",
    "    if find_prv_idx('证据',new_info_words):\n",
    "        prv_idx = int(find_prv_idx('证据',new_info_words))\n",
    "    prd_idx = get_prd_index(new_info_words)\n",
    "    prd_prv_range = get_bef_prv_till_prd(prd_idx,prv_idx)\n",
    "    \n",
    "    \n",
    "    if find_prv_idx('有',new_info_words[prd_prv_range[0]:prd_prv_range[1]]):\n",
    "        you_idx = int(find_prv_idx('有',new_info_words[prd_prv_range[0]:prd_prv_range[1]]))+ prd_prv_range[0]\n",
    "    prd_idx = get_prd_index(new_info_words)\n",
    "    prd_prv_range = get_bef_prv_till_prd(prd_idx,prv_idx)\n",
    "    print 'the prd_prv_range',prd_prv_range\n",
    "    print 'prv_idx',prv_idx\n",
    "    print 'prd_idx is',prd_idx\n",
    "    if you_idx:\n",
    "        prv_word_lst = new_info_words[you_idx:prv_idx+3]\n",
    "    else:\n",
    "        prv_word_lst = new_info_words[prd_prv_range[0]:prd_prv_range[1]+3]\n",
    "   \n",
    "    for pp in  prv_word_lst:print pp\n",
    "    #如果证据的那句话中有逗号和顿号，则提取这段话里面的内容，调用split_by_punc\n",
    "    #如果证据的那句话有顿号，且顿号后面是字符。则：\n",
    "    #提取其后所有冒号的位置，提取其后所有数字或者冒号的位置。形成tuple的列表\n",
    "    #然后便利list of tuples,调用split_by_punc提取其中的内容\n",
    "    if comma  in prv_word_lst or peroid in prv_word_lst:\n",
    "        print 'comma in'\n",
    "        prv_str = split_by_punc(prv_word_lst)\n",
    "    if colon in prv_word_lst:\n",
    "        print 'colon in'\n",
    "        pos_sgl_lst = pos_list[prv_idx:prv_idx+7]\n",
    "        print pos_sgl_lst\n",
    "        if 'm' not in pos_sgl_lst:\n",
    "            print  'number not after'\n",
    "            prv_str = split_by_punc(prv_word_lst)\n",
    "        elif 'm' in pos_sgl_lst and 'wp' in pos_sgl_lst:\n",
    "            print 'number in '\n",
    "            num_idx = pos_sgl_lst.index('m')\n",
    "            print num_idx\n",
    "            pp_start_idx = prv_idx + num_idx\n",
    "            print pp_start_idx\n",
    "            print new_info_words[pp_start_idx]\n",
    "            aft_num_seg_lst = new_info_words[pp_start_idx:]\n",
    "            print aft_num_seg_lst\n",
    "            aft_num_pos_lst = pos_list[pp_start_idx:]\n",
    "            aft_num_colon_idx = get_colon_index(aft_num_sge_lst)\n",
    "            aft_num_idx = get_num_pos_index(aft_num_pos_lst)\n",
    "            print aft_num_idx\n",
    "            print aft_num_colon_idx\n",
    "            new_split_range = get_aft_colon_split_range(aft_num_idx, aft_num_colon_idx)\n",
    "            print new_split_range\n",
    "            prv_lists = []\n",
    "        \n",
    "            for rr in new_split_range:\n",
    "                print 'rrr'\n",
    "                print rr[0]\n",
    "                print rr[1]\n",
    "                print aft_num_seg_lst[rr[0]]\n",
    "                print aft_num_seg_lst[rr[0]:rr[1]]\n",
    "                prv_list=split_by_punc(aft_num_seg_lst[rr[0]:rr[1]])\n",
    "                prv_lists.extend(prv_list)\n",
    "print prv_lists\n",
    "#law_df.loc[i,'prv'] =prv_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\xe6\\x9c\\x89', '\\xef\\xbc\\x9a']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prv_word_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if comma in prv_word_lst:print '11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if peroid in prv_word_lst:print '1111'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if colon in prv_word_lst:print '11111'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if comma in prv_word_lst or peroid in prv_word_lst:\n",
    "    print '222'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in aft_num_seg_lst[0:11]:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pr in prv_lists:\n",
    "    print pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prv_path ='/media/sherlock/new30/law/jun28InfoExtractor/tb_doc_prv.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prv_df = pd.read_csv(prv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "print prv_df.loc[1,'prv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "print eval(prv_df.loc[1,'prv'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str1 = '111'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'211121112'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1.join('222')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11133'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1+'33'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
